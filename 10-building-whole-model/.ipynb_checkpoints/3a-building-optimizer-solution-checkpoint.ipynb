{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing our Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll build out the component that finds the hypothesis function that minimizes the output of our loss component. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypothesis():\n",
    "    def __init__(self, coef_ = None, intercept_ = None, x_values = None):\n",
    "        self.coef_ = coef_\n",
    "        self.intercept_ = intercept_\n",
    "        self.x_values = x_values\n",
    "    \n",
    "    def predict(self, values):\n",
    "        return [self.predict_value(value) for value in values]\n",
    "    \n",
    "    def predict_value(self, value):\n",
    "        return self.coef_*value + self.intercept_\n",
    "    \n",
    "    def trace(self, mode = 'lines', name='predictions', text = []):\n",
    "        coef_text = f\"y = {self.coef_}x\"\n",
    "        intercept_text = f\" + {self.intercept_}\"\n",
    "        default_text = coef_text + intercept_text if self.intercept_ else coef_text\n",
    "        text = name or default_text\n",
    "        return {'x': self.x_values, 'y': self.predict(self.x_values),\n",
    "                'mode': mode, 'name': name, 'text': text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our Optimizer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's build an Optimizer class.  \n",
    "\n",
    "Let's take a look at the `__init__` function.  Note that the optimizer begins by taking in our data of the actual `x_values` and `y_values`.  It also takes in the y-intercept value.  This is because we will not tackle the more complicated problem of having our Optimizer find both parameters, it will only find the coefficient.\n",
    "\n",
    "The `start`, `stop` and `step_count` parameters will be explained further down below.  So will the `steps` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Optimizer:\n",
    "    def __init__(self, x_values, y_values, intercept):\n",
    "        self.x_values = x_values\n",
    "        self.y_values = y_values\n",
    "        self.intercept = intercept\n",
    "        \n",
    "    def set_coef_values(self, start, stop, n_steps):\n",
    "        self.coef_vals = np.linspace(start, stop, n_steps)\n",
    "    \n",
    "    def set_hypotheses(self):\n",
    "        self.hypotheses = [Hypothesis(coef, self.intercept, self.x_values) for coef in self.coef_vals]\n",
    "    \n",
    "    def set_losses(self):\n",
    "        self.losses = [Loss(hypothesis, self.x_values, self.y_values) for hypothesis in self.hypotheses]\n",
    "        \n",
    "    def find_min(self):\n",
    "        return min(self.losses, key = lambda loss: loss.rss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the goal of our optimizer is to find the value for our coefficient parameter that minimize the our `rss`.  The way that we'll do this is to create a list of Hypothesis instances, each with a sequential value of `m`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our first Hypothesis could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = 153\n",
    "x_values = [800, 1500, 2000, 3500, 4000]\n",
    "coef = .01\n",
    "\n",
    "hyp = Hypothesis(coef, intercept, x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second Hypothesis instance would have the same data except a slightly different coefficient parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = .02\n",
    "hyp = Hypothesis(coef, intercept, x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan is to create a list of these Hypothesis instances, and then use our Loss class to find the hypothesis with the smallest rss score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's where our steps method enters the picture: it generates a list of $m$ values to then pass through to create a list of Hypothesis instances.  To do so we just need to tell our Optimizer of a starting point, a stopping point, and a step size.  Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = 153\n",
    "coef = .01\n",
    "\n",
    "x_values = [800, 1500, 2000, 3500, 4000]\n",
    "outcomes = [330, 780, 1130, 1310, 1780]\n",
    "optimizer = Optimizer(x_values, outcomes, intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a list of steps.  Each one of these could be a different value for `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (stop-start)/step_size\n",
    "intercept = 153\n",
    "coef = .01\n",
    "\n",
    "x_values = [800, 1500, 2000, 3500, 4000]\n",
    "outcomes = [330, 780, 1130, 1310, 1780]\n",
    "optimizer = Optimizer(x_values, outcomes, intercept)\n",
    "\n",
    "optimizer.set_coef_values(0, 1, 11)\n",
    "optimizer.coef_vals\n",
    "# [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our coef values to create a number of Hypothesis instances, each with the same input values and y-intercept, but a different coefficient.  Create a `set_hypotheses` function, that creates a list of hypothesis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.set_hypotheses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of hypotheses, each with a different coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hypothesis at 0x128f3f190>,\n",
       " <__main__.Hypothesis at 0x128f3f150>,\n",
       " <__main__.Hypothesis at 0x128f3f210>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.hypotheses[0:3]\n",
    "# [<__main__.Hypothesis at 0x10bbe12b0>,\n",
    "#  <__main__.Hypothesis at 0x10bbe1630>,\n",
    "#  <__main__.Hypothesis at 0x10bbe1470>]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hyp.coef_ for hyp in optimizer.hypotheses[0:3]]\n",
    "# [0.0, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have an optimizer class, that can create a number of Hypotheses instances, each with a different coefficient.  What's left is to calculate the `rss` for each of these Hypotheses instances, and find the instance with the lowest `rss`.  \n",
    "\n",
    "Our hypotheses instances do not have the capability to calculate the `rss`.  That functionality lies with our `Loss` instances.  So we copy and paste our loss class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss():\n",
    "    def __init__(self, hypothesis, x_values, y_values):\n",
    "        self.hypothesis = hypothesis\n",
    "        self.x_values = x_values\n",
    "        self.y_values = y_values\n",
    "        \n",
    "    def errors(self):\n",
    "        expecteds = self.hypothesis.predict(self.x_values)\n",
    "        pairs = list(zip(self.y_values, expecteds))\n",
    "        return [actual - expected for actual, expected in pairs]\n",
    "    \n",
    "    def squared_errors(self):\n",
    "        return [error**2 for error in self.errors()]\n",
    "    \n",
    "    def rss(self):\n",
    "        return sum(self.squared_errors())\n",
    "    \n",
    "    def build_fig(self, layout = {}):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So in the `set_losses` method inside of our Optimizer class, use each of the hypothesis instances to create a list of Loss instances, and assign these loss instances to an attribute called `losses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Loss at 0x128f3fb50>,\n",
       " <__main__.Loss at 0x129149050>,\n",
       " <__main__.Loss at 0x129149090>]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.set_losses()\n",
    "optimizer.losses[0:3]\n",
    "\n",
    "# [<__main__.Loss at 0x10bc185c0>,\n",
    "#  <__main__.Loss at 0x10bc185f8>,\n",
    "#  <__main__.Loss at 0x10bc18630>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the losses should store the related hypothesis instances and should also store the x_values and y_values of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hypothesis': <__main__.Hypothesis at 0x128f3f190>,\n",
       " 'x_values': [800, 1500, 2000, 3500, 4000],\n",
       " 'y_values': [330, 780, 1130, 1310, 1780]}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.losses[0].__dict__\n",
    "\n",
    "# {'hypothesis': <__main__.Hypothesis at 0x10bbe12b0>,\n",
    "#  'x_values': [800, 1500, 2000, 3500, 4000],\n",
    "#  'y_values': [330, 780, 1130, 1310, 1780]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see a different hypothesis coefficient associated with each loss instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[loss.hypothesis.coef_ for loss in optimizer.losses[0:7]]\n",
    "\n",
    "# [0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a method called `find_min` that returns the Loss object with the lowest `rss`.  From there, we can find the related Hypothesis instance, and it's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coef_': 0.4, 'intercept_': 153, 'x_values': [800, 1500, 2000, 3500, 4000]}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = optimizer.find_min()\n",
    "loss.hypothesis.__dict__\n",
    "\n",
    "# {'coef_': 0.39, 'intercept_': 153, 'x_values': [800, 1500, 2000, 3500, 4000]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the hypothesis that minimizes our RSS the hypothesis with a coefficient of .39.  This is within one one-hundredth of what we calculated with SKLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38383838383838387, 153)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = 0\n",
    "stop = 1\n",
    "n_steps = 100\n",
    "\n",
    "x_values = [800, 1500, 2000, 3500, 4000]\n",
    "outcomes = [330, 780, 1130, 1310, 1780]\n",
    "intercept = 153\n",
    "\n",
    "optimizer = Optimizer(x_values, outcomes, intercept)\n",
    "optimizer.set_coef_values(start, stop, n_steps)\n",
    "optimizer.set_hypotheses()\n",
    "optimizer.set_losses()\n",
    "loss = optimizer.find_min()\n",
    "loss.hypothesis.coef_, loss.hypothesis.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add a function called `build_figure` to our loss instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure should return `figure` that has both a scatter plot, and the hypothesis function.  \n",
    "> Remember we can get the hypothesis trace from the Hypothesis class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.build_fig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer: <img src=\"./fig-no-errors.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can add the following lines to our function to return a plot with errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "hyp_trace = loss.hypothesis.trace()\n",
    "errors = dict(type='data', symmetric=False, array=self.errors())\n",
    "hyp_trace.update({'error_y': errors})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the updates, we should see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.build_fig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: <img src=\"./pred-observations.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll build out the component that finds the hypothesis function that minimizes the output of our loss component.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
