{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducing the loss function\n",
    "\n",
    "Before getting our hypothesis function closer to our observations, we first quantify just how far away our hypothesis function is.  This way we can at least get a sense of how good or bad we are performing.\n",
    "\n",
    "We quantify how good or bad we are doing simply by using an error metric, and then summing together the error at each observed result.  This sum is called our **loss function**.\n",
    "\n",
    "| spending        | actual t-shirt sales | expected t-shirt sales | actual - expected|\n",
    "| ------------- |:-------------:| :-------------:| :-------------:| \n",
    "|    2000        |380           | 300                               | -40 |\n",
    "|    3500        |445           | 525                               | -80 | \n",
    "|    4000      | 490            | 600                              |  -110 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above our $loss = -40 + -80 + -110 = -230$.\n",
    "\n",
    "Remember that this was for the hypothesis function $ sales =.15âˆ—ad\\_spend $ that each of our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use an optimization procedure to minimize the loss functoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the output of our loss function only applies to a specific hypothesis function.  We want to make the result of our loss function as close to zero as possible, so we need a way to minimize our loss function.  \n",
    "\n",
    "The way that we can do that is by finding the parameter -- above .15 is our parameter -- that minimizes our loss function.  Now our **optimization procedure** is how we find parameters that minimize our loss function.  There are different optimization procedures depending on the specific machine learning tool that we use - but here we can just do trial and error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
